{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analisys con NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6_gmTOaO3M8",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis con Redes Neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZlOPL_yO78q",
        "colab_type": "text"
      },
      "source": [
        "## Pasos Previos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlzGMNIvOcFy",
        "colab_type": "text"
      },
      "source": [
        "### Carga de datos en el entorno de ejecución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riBbKHMLBmzN",
        "colab_type": "text"
      },
      "source": [
        "Antes de nada, y ya que he utilizado un Colab, tengo que crear y copiar todos los archivos que necesito, y moverlos a los directorios apropiados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Hlawv5-wT_",
        "colab_type": "code",
        "outputId": "c357615a-8cea-4b56-cc90-ae7c88692c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/glove_word_embeddings\n",
        "!mkdir datasets\n",
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/glove_word_embeddings’: File exists\n",
            "mkdir: cannot create directory ‘datasets’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqW8BSw88sDL",
        "colab_type": "code",
        "outputId": "660121bb-120c-4c5a-d06f-2c54625ecb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#antes de ejecutar esto tienes que subir el archivo datasets al notebook\n",
        "\n",
        "!mv glove.6B.50d.txt data/glove_word_embeddings"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'glove.6B.50d.txt': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRzIJnAylFxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv resultados_modelos.csv results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hxGnprLo1x",
        "colab_type": "code",
        "outputId": "e7d0416d-f518-4dec-e72e-f790b8a41e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!mv train_sentiment_small.csv datasets\n",
        "!mv sentiment_dataset_limpio.csv datasets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'train_sentiment_small.csv': No such file or directory\n",
            "mv: cannot stat 'sentiment_dataset_limpio.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qskQf8pyLv8s",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0BRNRGsLdgq",
        "colab_type": "code",
        "outputId": "00a04a01-27c2-44c4-e4ec-411071b81899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pickle\n",
        "import json\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from random import sample\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lgQ1EdILOvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, SimpleRNN, LSTM, Dense, Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9BYS-mq90F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split             \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVqzgodPU0j",
        "colab_type": "text"
      },
      "source": [
        "### Variables de Entorno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFYyLtFMPXdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORDS = 5000\n",
        "maxlen = 100\n",
        "embedding_dim_glove = 50\n",
        "embedding_layer_dim = 100\n",
        "THRESHOLD = 0.5\n",
        "RESULTS_FILE = 'results/resultados_modelos.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBOA9GfLDwOE",
        "colab_type": "text"
      },
      "source": [
        "### Funciones Auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mop32td_LlfH",
        "colab_type": "text"
      },
      "source": [
        "Aqui defino unas funciones auxiliares para calcular metricas y presentar resultadios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frHvZcSBGXDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_row(df, row):\n",
        "    df.loc[-1] = row\n",
        "    df.index = df.index + 1  \n",
        "    return df.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCBlHc1z9ik0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertir_prediccion_en_array(prediccion):\n",
        "    i = 0\n",
        "\n",
        "    resp = []\n",
        "    while i < len(prediccion):\n",
        "        if prediccion[i] >= THRESHOLD:\n",
        "            e = 1.0\n",
        "        else:\n",
        "            e = 0.0\n",
        "        resp.append(e)\n",
        "        i += 1\n",
        "    return resp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rd9uObiRY4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(confmat):\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
        "    for i in range(confmat.shape[0]):\n",
        "        for j in range(confmat.shape[1]):\n",
        "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "    plt.xlabel('predicted label')\n",
        "    plt.ylabel('true label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xY-YmhiRY1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcula_metricas(confmat, plot=True):\n",
        "    \n",
        "    tn, fp, fn, tp = confmat.ravel()\n",
        "\n",
        "    acc = (tp+tn)/(tn + fp + fn + tp)\n",
        "    sen = tp/(tp+fn)\n",
        "    esp = tn/(tn+fp)\n",
        "    ppv = tp/(tp+fp)\n",
        "    fsc = 2*(sen*ppv/(sen+ppv))\n",
        "\n",
        "    print('ACC: ', acc)\n",
        "    print('SEN: ', sen)\n",
        "    print('ESP: ', esp)\n",
        "    print('PPV: ', ppv)\n",
        "    print('FSC: ', fsc)\n",
        "\n",
        "    if plot:\n",
        "        plt.bar(range(5),[acc,sen,esp,ppv,fsc])\n",
        "        plt.xticks(range(5),['ACC','SEN','ESP','PPV','FSC'])\n",
        "        plt.plot([-1, 6], [1, 1], color=(0.6, 0.6, 0.6), linestyle='--')\n",
        "        plt.xlim((-0.5,4.5))\n",
        "        plt.ylim((0,1.1))\n",
        "        plt.title('Metricas')\n",
        "        plt.show()\n",
        "    \n",
        "    metricas = [acc, sen,esp,ppv,fsc]\n",
        "    return metricas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hpckmnGD4PI",
        "colab_type": "text"
      },
      "source": [
        "## Carga y preparación de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qoE9AzGMI5Z",
        "colab_type": "text"
      },
      "source": [
        "Cargo el dataset pequeño. Esto es debido a que por incompatibilidad de alguna de las capas usadas con la GPU que tiene Colab, no se puede trabajar en GPU, con lo que para entrenar en un tiempo apropiado, uso un dataset pequeño (sacado de la sección 1.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT_GH2dDMo3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('datasets/train_sentiment_small.csv')\n",
        "\n",
        "# Descomentar para entrenar con el conjunto grande\n",
        "#df = pd.read_csv('datasets/sentiment_dataset_limpio.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRIgGS2iNi7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwlRY3QpNjtH",
        "colab_type": "code",
        "outputId": "d1908229-3632-4ce0-acf9-1db1fe881f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;MENTION&gt; lol ok thanks. anyway watcha doing?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;MENTION&gt; -- yeah, thank ya kindly!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;MENTION&gt;, is being a horrible friend. tears.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Jonas Brothers 3D Concert Movie is out on the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;MENTION&gt; k just call asap</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText\n",
              "0          1      <MENTION> lol ok thanks. anyway watcha doing?\n",
              "1          1                <MENTION> -- yeah, thank ya kindly!\n",
              "2          0      <MENTION>, is being a horrible friend. tears.\n",
              "3          0  Jonas Brothers 3D Concert Movie is out on the ...\n",
              "4          1                         <MENTION> k just call asap"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiC-jS3s90BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_text = df['SentimentText'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDEgGCn9z-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['Sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EohzqR6R9z7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_train,sentiment_test,y_train,y_test = train_test_split(\n",
        "                                                sentiment_text, y,  \n",
        "                                                test_size=0.25,  \n",
        "                                                random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HPFjFofuApV",
        "colab_type": "text"
      },
      "source": [
        "#Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLcRYC1x9z4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "tokenizer.fit_on_texts(sentiment_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iinJlu9t9z2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(sentiment_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentiment_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC9EbNxc9zzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding 1 because of  reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEbsuGnT9zt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmdRLNvVfQhk",
        "colab_type": "text"
      },
      "source": [
        "Para generar los wordembeddings uso [Glove](https://en.wikipedia.org/wiki/GloVe_(machine_learning)), que es un conjunto preentrenado de word embeddings.\n",
        "\n",
        "*GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih46h0xa9zrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  \n",
        "    # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-Epcl49-wa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = create_embedding_matrix('data/glove_word_embeddings/glove.6B.50d.txt' ,\n",
        "                                            tokenizer.word_index,  \n",
        "                                            embedding_dim_glove)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAXbA-8Zd9Cf",
        "colab_type": "text"
      },
      "source": [
        "## Red Neuronal Convolucional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFeLRMx3-wYK",
        "colab_type": "code",
        "outputId": "c745d4cb-568c-4eb0-ff76-4384c65604c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,220,529\n",
            "Trainable params: 1,220,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0f5g51Ue5A2",
        "colab_type": "text"
      },
      "source": [
        "Con todo el dataset se tarda un rato en entrenar (aprox 8 minutos por época), con el dataset pequeño 20s por época."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlGUSIRP-wRe",
        "colab_type": "code",
        "outputId": "66ad8cc1-bc8b-47b6-b7ae-f0671201b4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=5,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7500 samples, validate on 2500 samples\n",
            "Epoch 1/5\n",
            "7500/7500 [==============================] - 18s 2ms/step - loss: 0.5937 - acc: 0.6711 - val_loss: 0.5192 - val_acc: 0.7368\n",
            "Epoch 2/5\n",
            "7500/7500 [==============================] - 18s 2ms/step - loss: 0.4172 - acc: 0.8124 - val_loss: 0.5445 - val_acc: 0.7352\n",
            "Epoch 3/5\n",
            "7500/7500 [==============================] - 18s 2ms/step - loss: 0.2511 - acc: 0.9048 - val_loss: 0.6303 - val_acc: 0.7276\n",
            "Epoch 4/5\n",
            "7500/7500 [==============================] - 18s 2ms/step - loss: 0.1143 - acc: 0.9621 - val_loss: 0.8165 - val_acc: 0.7168\n",
            "Epoch 5/5\n",
            "7500/7500 [==============================] - 18s 2ms/step - loss: 0.0504 - acc: 0.9857 - val_loss: 0.9885 - val_acc: 0.7064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8-9YuQW-wNW",
        "colab_type": "code",
        "outputId": "995f89d7-04b8-459d-d8b2-42bda024dae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluamos\n",
        "train_acc = model.evaluate(X_train, y_train)[1]\n",
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 2s 324us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1PH4pQmQ-J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWOzhF7OQ-Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(y_test, prediccion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro4FxN9UQ-Cq",
        "colab_type": "code",
        "outputId": "b0884ee4-6269-418c-cf9c-99f340831f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_confusion_matrix(confmat)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0P8AFH45urkP3AIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBCSuvvoQ9_0",
        "colab_type": "code",
        "outputId": "a7da310f-206e-4875-ecd0-803832c14103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "metricas = calcula_metricas(confmat, plot=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC:  0.7064\n",
            "SEN:  0.7475862068965518\n",
            "ESP:  0.6495238095238095\n",
            "PPV:  0.7465564738292011\n",
            "FSC:  0.7470709855272227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVkiNggXl7pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_acc = metricas[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTV5yRYsQ98u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo = pd.read_csv(RESULTS_FILE)\n",
        "resultadosModelo = resultadosModelo.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en7hTz0e9zjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultado = ['CNN - Small Dataset', '-', train_acc, test_acc, confmat, metricas]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2PaGC0z9zgW",
        "colab_type": "code",
        "outputId": "daffb5b5-c316-43b0-d6e4-e1faa612a896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "add_row(resultadosModelo, resultado)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>parametros-optimos</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>acc_sen_esp_ppv_fsc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN - Small Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.992667</td>\n",
              "      <td>0.706400</td>\n",
              "      <td>[[682, 368], [366, 1084]]</td>\n",
              "      <td>[0.7064, 0.7475862068965518, 0.649523809523809...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM - Small Dataset</td>\n",
              "      <td>{'svm__C': 5.994842503189409, 'svm__gamma': 0....</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.733000</td>\n",
              "      <td>[[ 799  507]\\n [ 294 1400]]</td>\n",
              "      <td>[0.733, 0.8264462809917356, 0.611791730474732,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bayes - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'char', 'vect__max_df': 1.0...</td>\n",
              "      <td>0.717000</td>\n",
              "      <td>0.722333</td>\n",
              "      <td>[[ 909  397]\\n [ 436 1258]]</td>\n",
              "      <td>[0.7223333333333334, 0.7426210153482881, 0.696...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.653286</td>\n",
              "      <td>0.649667</td>\n",
              "      <td>[[ 479  827]\\n [ 224 1470]]</td>\n",
              "      <td>[0.6496666666666666, 0.8677685950413223, 0.366...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forestyes - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 23, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.668857</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>[[ 630  676]\\n [ 329 1365]]</td>\n",
              "      <td>[0.665, 0.8057851239669421, 0.4823889739663093...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Boosted Tree - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.714857</td>\n",
              "      <td>0.728667</td>\n",
              "      <td>[[ 784  522]\\n [ 292 1402]]</td>\n",
              "      <td>[0.7286666666666667, 0.8276269185360094, 0.600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bayes - Lemma - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'word', 'vect__max_df': 0.5...</td>\n",
              "      <td>0.686670</td>\n",
              "      <td>0.690333</td>\n",
              "      <td>[[ 704  602]\\n [ 327 1367]]</td>\n",
              "      <td>[0.6903333333333334, 0.806965761511216, 0.5390...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Decision Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.650236</td>\n",
              "      <td>0.647333</td>\n",
              "      <td>[[ 362  944]\\n [ 114 1580]]</td>\n",
              "      <td>[0.6473333333333333, 0.9327036599763873, 0.277...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Random Forestyes - Lemma - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 28, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.660237</td>\n",
              "      <td>0.664667</td>\n",
              "      <td>[[ 562  744]\\n [ 262 1432]]</td>\n",
              "      <td>[0.6646666666666666, 0.8453364817001181, 0.430...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Boosted Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.686955</td>\n",
              "      <td>0.701333</td>\n",
              "      <td>[[ 692  614]\\n [ 282 1412]]</td>\n",
              "      <td>[0.7013333333333334, 0.833530106257379, 0.5298...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SVM - Lemma - Small Dataset</td>\n",
              "      <td>{'svm__C': 1.0, 'svm__gamma': 0.03162277660168...</td>\n",
              "      <td>0.665524</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>[[ 508  798]\\n [ 147 1547]]</td>\n",
              "      <td>[0.685, 0.9132231404958677, 0.3889739663093415...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CNN - Big Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.927431</td>\n",
              "      <td>0.761541</td>\n",
              "      <td>[[ 7141  3821]\\n [ 2140 11896]]</td>\n",
              "      <td>[0.7615409232738619, 0.847534910230835, 0.6514...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Modelo  ...                                acc_sen_esp_ppv_fsc\n",
              "0                        CNN - Small Dataset  ...  [0.7064, 0.7475862068965518, 0.649523809523809...\n",
              "1                        SVM - Small Dataset  ...  [0.733, 0.8264462809917356, 0.611791730474732,...\n",
              "2                      Bayes - Small Dataset  ...  [0.7223333333333334, 0.7426210153482881, 0.696...\n",
              "3              Decision Tree - Small Dataset  ...  [0.6496666666666666, 0.8677685950413223, 0.366...\n",
              "4           Random Forestyes - Small Dataset  ...  [0.665, 0.8057851239669421, 0.4823889739663093...\n",
              "5               Boosted Tree - Small Dataset  ...  [0.7286666666666667, 0.8276269185360094, 0.600...\n",
              "6              Bayes - Lemma - Small Dataset  ...  [0.6903333333333334, 0.806965761511216, 0.5390...\n",
              "7      Decision Tree - Lemma - Small Dataset  ...  [0.6473333333333333, 0.9327036599763873, 0.277...\n",
              "8   Random Forestyes - Lemma - Small Dataset  ...  [0.6646666666666666, 0.8453364817001181, 0.430...\n",
              "9       Boosted Tree - Lemma - Small Dataset  ...  [0.7013333333333334, 0.833530106257379, 0.5298...\n",
              "10               SVM - Lemma - Small Dataset  ...  [0.685, 0.9132231404958677, 0.3889739663093415...\n",
              "11                         CNN - Big Dataset  ...  [0.7615409232738619, 0.847534910230835, 0.6514...\n",
              "\n",
              "[12 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9RVeMqAmgtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo.to_csv(RESULTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTGhz20Omgqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St5EB1QXmgnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uws6Y5VqntFY",
        "colab_type": "text"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC5xFzzcsSBS",
        "colab_type": "code",
        "outputId": "f61918d0-dc7f-409e-8662-2f89a81021de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim, input_length=maxlen))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 1,235,605\n",
            "Trainable params: 1,235,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vilTfd_Pmghz",
        "colab_type": "code",
        "outputId": "851da3af-eefc-44ab-9df1-6ef3fbdeb5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7500 samples, validate on 2500 samples\n",
            "Epoch 1/3\n",
            "6848/7500 [==========================>...] - ETA: 2s - loss: 7.0237 - acc: 0.5594"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CWZKz_LqFAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjlCDgoPqE78",
        "colab_type": "code",
        "outputId": "07ae9f95-ef37-412a-e168-5d106538b92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,220,529\n",
            "Trainable params: 1,220,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SaPcdRnqE31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrCnAuc2mgk6",
        "colab_type": "code",
        "outputId": "f44b3cc4-db8a-47cd-b767-194e86124369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,235,601\n",
            "Trainable params: 1,235,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgiiX3N_mgef",
        "colab_type": "code",
        "outputId": "b0feded3-3eca-4d24-a3f5-6ea155367f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluamos\n",
        "train_acc = model.evaluate(X_train, y_train)[1]\n",
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 6s 819us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxmIfHqdpIJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEdFHo28pIGS",
        "colab_type": "code",
        "outputId": "9d5dbd5a-5e03-41f7-a914-61181c72db90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "prediccion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2vCrsYLpIDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb34V64NpIBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb0GC3yupH-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olAddJp-pH7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFh3qvjVpH5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tQez8IvpH2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wBdzFAnpHzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgsOmb0-mgVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItdRVvtmN4x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "for row in df.iterrows():\n",
        "    ix, data = row\n",
        "    dataset.append((data[1], data[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPh3vfsIOTEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fRpoCq7OKv5",
        "colab_type": "code",
        "outputId": "bf2d5463-0c89-479a-df5b-faf0a287045d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tokens = []\n",
        "tokenized = []\n",
        "for x, y in dataset:\n",
        "    x_t = nlp(x)\n",
        "    toks = [t.text for t in x_t]\n",
        "    tokens+= toks\n",
        "    tokenized.append((toks, y))\n",
        "    \n",
        "vocab_counter = Counter(tokens)\n",
        "vocab = set(tokens)\n",
        "print('Num de features a usar: ', len(vocab))  \n",
        "print(len(tokenized))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num de features a usar:  16280\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOTUolqrOQnt",
        "colab_type": "code",
        "outputId": "d5227e72-c1e1-41be-dd20-9e543a0a22c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "maxlen = max([len(x) for x, _ in tokenized])\n",
        "maxlen"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIL8cAcoOv8d",
        "colab_type": "code",
        "outputId": "bd12c43b-f28b-45bf-9472-dcaf7e6b8c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lens = [len(x) for x, _ in tokenized]\n",
        "median = np.median(np.array(lens))\n",
        "mean = np.mean(np.array(lens))\n",
        "maxlen = int(median)*2\n",
        "print(median, mean, maxlen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17.0 17.8821 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mmVUwA0Ov5m",
        "colab_type": "code",
        "outputId": "c380700c-2bdc-4256-c1fd-ff95e32e75f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenized_filtered = [(x, y) for x, y in tokenized if len(x) < maxlen]\n",
        "len(tokenized_filtered)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MohXPNVOv23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construir el vocabulario como siempre\n",
        "w2id = {k:i for i, k in enumerate(vocab)}\n",
        "w2id['<UNK>'] = len(w2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N63cG0nwOvzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['POS', 'NEG']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6zoar4DOvw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l2id = {label:i for i, label in enumerate(labels)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gox8sGZ_OvuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxUV4cu7Ovrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ready = []\n",
        "for x, y in tokenized_filtered:\n",
        "    sentence = np.zeros((maxlen))\n",
        "    label = np.zeros((len(labels)))\n",
        "    label[int(y)-1] = 1\n",
        "    for i, t in enumerate(x):\n",
        "        sentence[i] = w2id[t] if t in vocab_counter and vocab_counter[t]>=5 else w2id['<UNK>']\n",
        "    input_ready.append((sentence,label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv-Ifi36Ovo0",
        "colab_type": "code",
        "outputId": "a6716663-6bed-41e4-e558-484e5ad827e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_ready[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vUw6rlaOvly",
        "colab_type": "code",
        "outputId": "35ad94d2-188b-47f2-8b9a-2c51e89e1907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "splits = split_train_val_test(input_ready)\n",
        "print(splits['train'][0].shape)\n",
        "print(splits['train'][1].shape)\n",
        "splits['train'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7772, 34)\n",
            "(7772, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6656.,  4920.,  7875., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.],\n",
              "       ...,\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  8604., 14341., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsIaeIt0P8Pw",
        "colab_type": "code",
        "outputId": "ababbd6e-b74c-43e4-fe7c-dd6067d3ba24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "splits['train'][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsJYPIDlP8Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.layers import Flatten, Input\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCyeQlnhP8Jq",
        "colab_type": "code",
        "outputId": "0d2f3c7d-f07b-453c-e37b-080e5008cc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "input_layer = Input(shape=(maxlen,) )\n",
        "embedding = Embedding(output_dim=100, input_dim=len(w2id), input_length=maxlen)(input_layer)\n",
        "dense_1 = Dense(300, activation='relu')(embedding)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(300, activation='relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "out = Dense(len(l2id), activation='softmax')(drop_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 34)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 34, 100)           1628100   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 34, 300)           30300     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 34, 300)           90300     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 34, 2)             602       \n",
            "=================================================================\n",
            "Total params: 1,749,302\n",
            "Trainable params: 1,749,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IueINoyxJcp6",
        "colab_type": "text"
      },
      "source": [
        "## 1.2.3 Deep Averaging Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVGNmCFrP8Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1FAukl9P8D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Average, average, Lambda\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxagPzwjP8BJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_aware_mean(x):\n",
        "    # recreate the masks - all zero rows have been masked\n",
        "    mask = K.not_equal(K.sum(K.abs(x), axis=2, keepdims=True), 0)\n",
        "    # number of that rows are not all zeros\n",
        "    n = K.sum(K.cast(mask, 'float32'), axis=1, keepdims=False)\n",
        "    # compute mask-aware mean of x\n",
        "    x_mean = K.sum(x, axis=1, keepdims=False) / n\n",
        "    return x_mean\n",
        "\n",
        "def mask_aware_mean_output_shape(input_shape):\n",
        "    shape = list(input_shape)\n",
        "    assert len(shape) == 3\n",
        "    return (shape[0], shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzxHmpkJP7-Y",
        "colab_type": "code",
        "outputId": "1d2f96a1-895e-47e6-dd8b-910c5073ef96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "source": [
        "input_layer = Input(shape=(maxlen,) )\n",
        "embedding = Embedding(output_dim=100, input_dim=len(w2id), input_length=maxlen)(input_layer)\n",
        "doc_representation = Lambda(mask_aware_mean, mask_aware_mean_output_shape, name='embedding_average')(embedding)\n",
        "dense_1 = Dense(100, activation='relu')(doc_representation)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(100, activation='relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "out = Dense(len(l2id), activation='softmax')(drop_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 34)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 34, 100)           1628100   \n",
            "_________________________________________________________________\n",
            "embedding_average (Lambda)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 1,648,502\n",
            "Trainable params: 1,648,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGr9gcb5P77W",
        "colab_type": "code",
        "outputId": "b7881461-bf39-4ca3-8463-af0b7056921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_ready = []\n",
        "for x, y in tokenized_filtered:\n",
        "    sentence = np.zeros((maxlen))\n",
        "    label = np.zeros((len(labels)))\n",
        "    label[int(y)-1] = 1\n",
        "    for i, t in enumerate(x):\n",
        "        sentence[i] = w2id[t] if t in vocab_counter and vocab_counter[t]>2 else w2id['<UNK>']\n",
        "    input_ready.append((sentence,label))\n",
        "    \n",
        "splits = split_train_val_test(input_ready)\n",
        "print(splits['train'][0].shape)\n",
        "print(splits['train'][1].shape)\n",
        "\n",
        "    \n",
        "\n",
        "model.fit(splits['train'][0], splits['train'][1],\n",
        "          epochs=50,\n",
        "          batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7772, 34)\n",
            "(7772, 2)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/50\n",
            "7772/7772 [==============================] - 5s 700us/step - loss: 0.6522 - acc: 0.6099\n",
            "Epoch 2/50\n",
            "7772/7772 [==============================] - 2s 276us/step - loss: 0.5488 - acc: 0.7307\n",
            "Epoch 3/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.5026 - acc: 0.7608\n",
            "Epoch 4/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.4760 - acc: 0.7764\n",
            "Epoch 5/50\n",
            "7772/7772 [==============================] - 2s 291us/step - loss: 0.4600 - acc: 0.7953\n",
            "Epoch 6/50\n",
            "7772/7772 [==============================] - 2s 278us/step - loss: 0.4493 - acc: 0.7979\n",
            "Epoch 7/50\n",
            "7772/7772 [==============================] - 2s 278us/step - loss: 0.4473 - acc: 0.8037\n",
            "Epoch 8/50\n",
            "7772/7772 [==============================] - 2s 276us/step - loss: 0.4314 - acc: 0.8107\n",
            "Epoch 9/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.4265 - acc: 0.8155\n",
            "Epoch 10/50\n",
            "7772/7772 [==============================] - 2s 290us/step - loss: 0.4224 - acc: 0.8163\n",
            "Epoch 11/50\n",
            "7772/7772 [==============================] - 2s 293us/step - loss: 0.4126 - acc: 0.8226\n",
            "Epoch 12/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.4083 - acc: 0.8244\n",
            "Epoch 13/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.4055 - acc: 0.8250\n",
            "Epoch 14/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.3982 - acc: 0.8341\n",
            "Epoch 15/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.3907 - acc: 0.8353\n",
            "Epoch 16/50\n",
            "7772/7772 [==============================] - 2s 277us/step - loss: 0.3827 - acc: 0.8433\n",
            "Epoch 17/50\n",
            "7772/7772 [==============================] - 2s 276us/step - loss: 0.3748 - acc: 0.8471\n",
            "Epoch 18/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.3671 - acc: 0.8515\n",
            "Epoch 19/50\n",
            "7772/7772 [==============================] - 2s 287us/step - loss: 0.3555 - acc: 0.8567\n",
            "Epoch 20/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.3452 - acc: 0.8646\n",
            "Epoch 21/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.3350 - acc: 0.8657\n",
            "Epoch 22/50\n",
            "7772/7772 [==============================] - 2s 290us/step - loss: 0.3297 - acc: 0.8704\n",
            "Epoch 23/50\n",
            "7772/7772 [==============================] - 2s 275us/step - loss: 0.3232 - acc: 0.8782\n",
            "Epoch 24/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.3032 - acc: 0.8827\n",
            "Epoch 25/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.2999 - acc: 0.8855\n",
            "Epoch 26/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.2937 - acc: 0.8882\n",
            "Epoch 27/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.2855 - acc: 0.8917\n",
            "Epoch 28/50\n",
            "7772/7772 [==============================] - 2s 279us/step - loss: 0.2785 - acc: 0.8942\n",
            "Epoch 29/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.2695 - acc: 0.8968\n",
            "Epoch 30/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.2644 - acc: 0.9012\n",
            "Epoch 31/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.2589 - acc: 0.9008\n",
            "Epoch 32/50\n",
            "7772/7772 [==============================] - 2s 272us/step - loss: 0.2503 - acc: 0.9086\n",
            "Epoch 33/50\n",
            "7772/7772 [==============================] - 2s 279us/step - loss: 0.2422 - acc: 0.9099\n",
            "Epoch 34/50\n",
            "7772/7772 [==============================] - 2s 290us/step - loss: 0.2345 - acc: 0.9108\n",
            "Epoch 35/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.2350 - acc: 0.9133\n",
            "Epoch 36/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.2278 - acc: 0.9189\n",
            "Epoch 37/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.2242 - acc: 0.9216\n",
            "Epoch 38/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.2195 - acc: 0.9207\n",
            "Epoch 39/50\n",
            "7772/7772 [==============================] - 2s 279us/step - loss: 0.2120 - acc: 0.9247\n",
            "Epoch 40/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.2140 - acc: 0.9247\n",
            "Epoch 41/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.2144 - acc: 0.9265\n",
            "Epoch 42/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.2064 - acc: 0.9272\n",
            "Epoch 43/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.1964 - acc: 0.9309\n",
            "Epoch 44/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.1934 - acc: 0.9343\n",
            "Epoch 45/50\n",
            "7772/7772 [==============================] - 2s 289us/step - loss: 0.1947 - acc: 0.9323\n",
            "Epoch 46/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.1939 - acc: 0.9327\n",
            "Epoch 47/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.1865 - acc: 0.9395\n",
            "Epoch 48/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.1889 - acc: 0.9406\n",
            "Epoch 49/50\n",
            "7772/7772 [==============================] - 2s 300us/step - loss: 0.1780 - acc: 0.9418\n",
            "Epoch 50/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.1841 - acc: 0.9407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f502c98ff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBESqdQXOvgL",
        "colab_type": "code",
        "outputId": "4c4db739-5b40-4f69-9717-9e6e6482424c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_acc = model.evaluate(splits['train'][0], splits['train'][1])[1]\n",
        "prediction = model.predict(splits['test'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7772/7772 [==============================] - 0s 44us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gqM5GbU9xyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)\n",
        "testeo = convertir_prediccion_en_array(splits['test'][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPhvesUl9xvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(testeo, prediccion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA-GNic2DLB3",
        "colab_type": "code",
        "outputId": "4cc76d8a-2c45-4ae2-eb40-beb830e2aec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_confusion_matrix(confmat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wd+yIuzTUHUxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR7I0VyZRYyn",
        "colab_type": "code",
        "outputId": "6458d814-1085-4122-999a-5dabde13595b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "metricas = calcula_metricas(confmat)\n",
        "test_acc = metricas[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC:  0.6886258363355635\n",
            "SEN:  0.5950118764845606\n",
            "ESP:  0.7602179836512262\n",
            "PPV:  0.6549019607843137\n",
            "FSC:  0.6235220908525202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/qBmvyKmlA6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krgr_V5qF8kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo = pd.read_csv('resultados_modelos.csv')\n",
        "resultadosModelo = resultadosModelo.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8sMkz0zGi27",
        "colab_type": "code",
        "outputId": "5bb634cf-b667-4f00-ad60-66141d32c639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "resultado = ['RDN - Small Dataset', '-', train_acc, test_acc,\n",
        "             confmat, metricas]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-67efdd0780ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m resultado = ['RDN - Small Dataset', '-', train_acc, test_acc,\n\u001b[0m\u001b[1;32m      2\u001b[0m              confmat, metricas]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taNNexR_F8gG",
        "colab_type": "code",
        "outputId": "7c5fb52f-a89c-48cb-f281-605ad7d91b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "source": [
        "add_row(resultadosModelo, resultado)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>parametros-optimos</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>acc_sen_esp_ppv_fsc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RDN - Small Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.956897</td>\n",
              "      <td>0.688626</td>\n",
              "      <td>[[837, 264], [341, 501]]</td>\n",
              "      <td>[0.6886258363355635, 0.5950118764845606, 0.760...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM - Small Dataset</td>\n",
              "      <td>{'svm__C': 5.994842503189409, 'svm__gamma': 0....</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.733000</td>\n",
              "      <td>[[ 799  507]\\n [ 294 1400]]</td>\n",
              "      <td>[0.733, 0.8264462809917356, 0.611791730474732,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bayes - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'char', 'vect__max_df': 1.0...</td>\n",
              "      <td>0.717000</td>\n",
              "      <td>0.722333</td>\n",
              "      <td>[[ 909  397]\\n [ 436 1258]]</td>\n",
              "      <td>[0.7223333333333334, 0.7426210153482881, 0.696...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.653286</td>\n",
              "      <td>0.649667</td>\n",
              "      <td>[[ 479  827]\\n [ 224 1470]]</td>\n",
              "      <td>[0.6496666666666666, 0.8677685950413223, 0.366...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forestyes - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 23, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.668857</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>[[ 630  676]\\n [ 329 1365]]</td>\n",
              "      <td>[0.665, 0.8057851239669421, 0.4823889739663093...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Boosted Tree - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.714857</td>\n",
              "      <td>0.728667</td>\n",
              "      <td>[[ 784  522]\\n [ 292 1402]]</td>\n",
              "      <td>[0.7286666666666667, 0.8276269185360094, 0.600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bayes - Lemma - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'word', 'vect__max_df': 0.5...</td>\n",
              "      <td>0.686670</td>\n",
              "      <td>0.690333</td>\n",
              "      <td>[[ 704  602]\\n [ 327 1367]]</td>\n",
              "      <td>[0.6903333333333334, 0.806965761511216, 0.5390...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Decision Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.650236</td>\n",
              "      <td>0.647333</td>\n",
              "      <td>[[ 362  944]\\n [ 114 1580]]</td>\n",
              "      <td>[0.6473333333333333, 0.9327036599763873, 0.277...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Random Forestyes - Lemma - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 28, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.660237</td>\n",
              "      <td>0.664667</td>\n",
              "      <td>[[ 562  744]\\n [ 262 1432]]</td>\n",
              "      <td>[0.6646666666666666, 0.8453364817001181, 0.430...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Boosted Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.686955</td>\n",
              "      <td>0.701333</td>\n",
              "      <td>[[ 692  614]\\n [ 282 1412]]</td>\n",
              "      <td>[0.7013333333333334, 0.833530106257379, 0.5298...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SVM - Lemma - Small Dataset</td>\n",
              "      <td>{'svm__C': 1.0, 'svm__gamma': 0.03162277660168...</td>\n",
              "      <td>0.665524</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>[[ 508  798]\\n [ 147 1547]]</td>\n",
              "      <td>[0.685, 0.9132231404958677, 0.3889739663093415...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Modelo  ...                                acc_sen_esp_ppv_fsc\n",
              "0                        RDN - Small Dataset  ...  [0.6886258363355635, 0.5950118764845606, 0.760...\n",
              "1                        SVM - Small Dataset  ...  [0.733, 0.8264462809917356, 0.611791730474732,...\n",
              "2                      Bayes - Small Dataset  ...  [0.7223333333333334, 0.7426210153482881, 0.696...\n",
              "3              Decision Tree - Small Dataset  ...  [0.6496666666666666, 0.8677685950413223, 0.366...\n",
              "4           Random Forestyes - Small Dataset  ...  [0.665, 0.8057851239669421, 0.4823889739663093...\n",
              "5               Boosted Tree - Small Dataset  ...  [0.7286666666666667, 0.8276269185360094, 0.600...\n",
              "6              Bayes - Lemma - Small Dataset  ...  [0.6903333333333334, 0.806965761511216, 0.5390...\n",
              "7      Decision Tree - Lemma - Small Dataset  ...  [0.6473333333333333, 0.9327036599763873, 0.277...\n",
              "8   Random Forestyes - Lemma - Small Dataset  ...  [0.6646666666666666, 0.8453364817001181, 0.430...\n",
              "9       Boosted Tree - Lemma - Small Dataset  ...  [0.7013333333333334, 0.833530106257379, 0.5298...\n",
              "10               SVM - Lemma - Small Dataset  ...  [0.685, 0.9132231404958677, 0.3889739663093415...\n",
              "\n",
              "[11 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VkWMl4IF8dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo.to_csv('datasets/resultados_modelos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V-yGQLUF8Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDI2lCZnF8V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0yjzULBKM-8",
        "colab_type": "text"
      },
      "source": [
        "## 1.2.3 Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MenJhgt8F8NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers import Input, Embedding, Concatenate\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys9hYdkNefO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = maxlen\n",
        "EMBEDDING_DIM = embedding_dim\n",
        "len(w2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u15P1yOneaP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(len(w2id) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBQbun2wdsSh",
        "colab_type": "code",
        "outputId": "2704e8fe-e845-482d-f8d6-5f82d6d21b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
        "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "l_flat = Flatten()(l_pool3)\n",
        "l_dense = Dense(128, activation='relu')(l_flat)\n",
        "preds = Dense(len(macronum), activation='softmax')(l_dense)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 2 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,2,1,128].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4e54347c9f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_cov1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml_cov2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ml_pool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_cov2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0ml_cov3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_pool2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0ml_pool3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_cov3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# global max pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_axis\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# remove dummy last dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    111\u001b[0m                           padding, data_format):\n\u001b[1;32m    112\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m--> 113\u001b[0;31m                           padding, data_format, pool_mode='max')\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   4267\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   4268\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4269\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   4270\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4271\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   3754\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3755\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3756\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5670\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5671\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5672\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5673\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5674\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 2 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,2,1,128]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idOrqVHeKYQz",
        "colab_type": "code",
        "outputId": "1348eebe-3ec2-404f-e13b-8f45f55075a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "input_layer = Input(shape=(maxlen,) )# maxlen\n",
        "embedding = Embedding(output_dim=embedding_dim, input_dim=len(w2id), input_length=maxlen)(input_layer)#w2id maxlen\n",
        "\n",
        "conv_1 = Conv1D(filters=50, kernel_size=1, strides=1, activation='relu', padding='valid')(embedding)\n",
        "mp_1 = GlobalMaxPooling1D()(conv_1)\n",
        "\n",
        "conv_2 = Conv1D(filters=50, kernel_size=2, strides=1, activation='relu', padding='valid')(embedding)\n",
        "mp_2 = GlobalMaxPooling1D()(conv_2)\n",
        "\n",
        "conv_5 = Conv1D(filters=50, kernel_size=5, strides=1, activation='relu', padding='valid')(embedding)\n",
        "mp_5 = GlobalMaxPooling1D()(conv_5)\n",
        "\n",
        "doc_representation = Concatenate()([mp_1, mp_2, mp_5])\n",
        "\n",
        "dense_1 = Dense(100, activation='relu')(doc_representation)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(100, activation='relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "out = Dense(len(l2id), activation='softmax')(drop_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 34)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 100)      1628100     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 34, 50)       5050        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 33, 50)       10050       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 30, 50)       25050       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 50)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 50)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 50)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 150)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          15100       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 100)          10100       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            202         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,693,652\n",
            "Trainable params: 1,693,652\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP7OY0FtgP2k",
        "colab_type": "code",
        "outputId": "53a90b20-d4ef-4697-98f6-1fdf857a2406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "print(splits['train'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6656.  4920.  7875. ...     0.     0.     0.]\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]\n",
            " ...\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]\n",
            " [ 9182.  8604. 14341. ...     0.     0.     0.]\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFr0AQx9KYH8",
        "colab_type": "code",
        "outputId": "e52325eb-9b70-4157-f181-61707ef21281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(splits['train'][0].shape)\n",
        "print(splits['train'][1].shape)\n",
        "    \n",
        "\n",
        "model.fit(splits['train'][0], splits['train'][1],\n",
        "          epochs=10,\n",
        "          batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7772, 34)\n",
            "(7772, 2)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "7772/7772 [==============================] - 16s 2ms/step - loss: 0.6662 - acc: 0.6020\n",
            "Epoch 2/10\n",
            "7772/7772 [==============================] - 14s 2ms/step - loss: 0.5886 - acc: 0.6981\n",
            "Epoch 3/10\n",
            "7772/7772 [==============================] - 14s 2ms/step - loss: 0.6284 - acc: 0.6971\n",
            "Epoch 4/10\n",
            "7772/7772 [==============================] - 15s 2ms/step - loss: 3.4518 - acc: 0.6143\n",
            "Epoch 5/10\n",
            "7772/7772 [==============================] - 17s 2ms/step - loss: 6.8469 - acc: 0.5704\n",
            "Epoch 6/10\n",
            "7772/7772 [==============================] - 15s 2ms/step - loss: 7.5071 - acc: 0.5306\n",
            "Epoch 7/10\n",
            "7772/7772 [==============================] - 15s 2ms/step - loss: 9.1049 - acc: 0.4349\n",
            "Epoch 8/10\n",
            "7772/7772 [==============================] - 13s 2ms/step - loss: 8.8911 - acc: 0.4476\n",
            "Epoch 9/10\n",
            "7772/7772 [==============================] - 13s 2ms/step - loss: 7.8750 - acc: 0.5094\n",
            "Epoch 10/10\n",
            "7772/7772 [==============================] - 13s 2ms/step - loss: 9.0265 - acc: 0.4397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24d4a4ee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXuwzJrQKXxz",
        "colab_type": "code",
        "outputId": "3d56c477-eac7-4403-afc8-7ae14eb3e233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_acc = model.evaluate(splits['train'][0], splits['train'][1])[1]\n",
        "prediction = model.predict(splits['test'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7772/7772 [==============================] - 1s 128us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPNTcTZhKXul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)\n",
        "testeo = convertir_prediccion_en_array(splits['test'][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcLiDZxzKXrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(testeo, prediccion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPQKgLvaKXoc",
        "colab_type": "code",
        "outputId": "2fff593b-7330-484e-e518-f0845f47e112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "source": [
        "metricas = calcula_metricas(confmat)\n",
        "test_acc = metricas[0]\n",
        "plot_confusion_matrix(confmat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC:  0.4333504889346372\n",
            "SEN:  1.0\n",
            "ESP:  0.0\n",
            "PPV:  0.4333504889346372\n",
            "FSC:  0.6046678635547577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1CDDXZIaZLhLUoMMd0lqkOEuSQ36/9dOiiTnXNL9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0BDAg4ADf1/Ri7qf+twXqQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZfc5s4KXgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultado = ['CNN - Small Dataset', '-', train_acc, test_acc,\n",
        "             confmat, metricas]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFGTDT_EOva5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(splits['train'][0], splits['train'][1],\n",
        "          epochs=50,\n",
        "          batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}