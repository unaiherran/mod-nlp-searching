{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.2 - Sentiment Analisys con NN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BAXbA-8Zd9Cf",
        "F_IeDTCMfZg0",
        "o0yjzULBKM-8",
        "IueINoyxJcp6",
        "j2pbo2IwMCOq"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6_gmTOaO3M8",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis con Redes Neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZlOPL_yO78q",
        "colab_type": "text"
      },
      "source": [
        "## Pasos Previos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlzGMNIvOcFy",
        "colab_type": "text"
      },
      "source": [
        "### Carga de datos en el entorno de ejecución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riBbKHMLBmzN",
        "colab_type": "text"
      },
      "source": [
        "Antes de nada, y ya que he utilizado un Colab, tengo que crear y copiar todos los archivos que necesito, y moverlos a los directorios apropiados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Hlawv5-wT_",
        "colab_type": "code",
        "outputId": "4924766c-b830-4a15-a625-e29c4ac5b446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/glove_word_embeddings\n",
        "!mkdir datasets\n",
        "!mkdir results"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘data/glove_word_embeddings’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwxvcBMEDMzh",
        "colab_type": "text"
      },
      "source": [
        "Hay que subir:\n",
        "\n",
        "```glove.6B.50d.txt```\n",
        "\n",
        "`resultados_modelos.csv`\n",
        "\n",
        "`sentiment_dataset_limpio.csv`  \n",
        "\n",
        "`train_sentiment_small.csv`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqW8BSw88sDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#antes de ejecutar esto tienes que subir el archivo datasets al notebook\n",
        "\n",
        "!mv glove.6B.50d.txt data/glove_word_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRzIJnAylFxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv resultados_modelos.csv results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hxGnprLo1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv train_sentiment_small.csv datasets\n",
        "!mv sentiment_dataset_limpio.csv datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qskQf8pyLv8s",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0BRNRGsLdgq",
        "colab_type": "code",
        "outputId": "c6e002ce-6b30-4a31-87ef-b88594159cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pickle\n",
        "import json\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from random import sample\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lgQ1EdILOvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, SimpleRNN, LSTM, Dense, Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9BYS-mq90F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split             \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVqzgodPU0j",
        "colab_type": "text"
      },
      "source": [
        "### Variables de Entorno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFYyLtFMPXdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORDS = 5000\n",
        "maxlen = 100\n",
        "embedding_dim_glove = 50\n",
        "embedding_layer_dim = 100\n",
        "THRESHOLD = 0.5\n",
        "RESULTS_FILE = 'results/resultados_modelos.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBOA9GfLDwOE",
        "colab_type": "text"
      },
      "source": [
        "### Funciones Auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mop32td_LlfH",
        "colab_type": "text"
      },
      "source": [
        "Aqui defino unas funciones auxiliares para calcular metricas y presentar resultadios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frHvZcSBGXDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_row(df, row):\n",
        "    df.loc[-1] = row\n",
        "    df.index = df.index + 1  \n",
        "    return df.sort_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCBlHc1z9ik0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertir_prediccion_en_array(prediccion):\n",
        "    i = 0\n",
        "\n",
        "    resp = []\n",
        "    while i < len(prediccion):\n",
        "        if prediccion[i] >= THRESHOLD:\n",
        "            e = 1.0\n",
        "        else:\n",
        "            e = 0.0\n",
        "        resp.append(e)\n",
        "        i += 1\n",
        "    return resp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rd9uObiRY4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(confmat):\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
        "    for i in range(confmat.shape[0]):\n",
        "        for j in range(confmat.shape[1]):\n",
        "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "    plt.xlabel('predicted label')\n",
        "    plt.ylabel('true label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xY-YmhiRY1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcula_metricas(confmat, plot=True):\n",
        "    \n",
        "    tn, fp, fn, tp = confmat.ravel()\n",
        "\n",
        "    acc = (tp+tn)/(tn + fp + fn + tp)\n",
        "    sen = tp/(tp+fn)\n",
        "    esp = tn/(tn+fp)\n",
        "    ppv = tp/(tp+fp)\n",
        "    fsc = 2*(sen*ppv/(sen+ppv))\n",
        "\n",
        "    print('ACC: ', acc)\n",
        "    print('SEN: ', sen)\n",
        "    print('ESP: ', esp)\n",
        "    print('PPV: ', ppv)\n",
        "    print('FSC: ', fsc)\n",
        "\n",
        "    if plot:\n",
        "        plt.bar(range(5),[acc,sen,esp,ppv,fsc])\n",
        "        plt.xticks(range(5),['ACC','SEN','ESP','PPV','FSC'])\n",
        "        plt.plot([-1, 6], [1, 1], color=(0.6, 0.6, 0.6), linestyle='--')\n",
        "        plt.xlim((-0.5,4.5))\n",
        "        plt.ylim((0,1.1))\n",
        "        plt.title('Metricas')\n",
        "        plt.show()\n",
        "    \n",
        "    metricas = [acc, sen,esp,ppv,fsc]\n",
        "    return metricas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hpckmnGD4PI",
        "colab_type": "text"
      },
      "source": [
        "## Carga y preparación de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qoE9AzGMI5Z",
        "colab_type": "text"
      },
      "source": [
        "Cargo el dataset pequeño. Esto es debido a que por incompatibilidad de alguna de las capas usadas con la GPU que tiene Colab, no se puede trabajar en GPU, con lo que para entrenar en un tiempo apropiado, uso un dataset pequeño (sacado de la sección 1.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT_GH2dDMo3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('datasets/train_sentiment_small.csv')\n",
        "\n",
        "# Descomentar para entrenar con el conjunto grande\n",
        "#df = pd.read_csv('datasets/sentiment_dataset_limpio.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRIgGS2iNi7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwlRY3QpNjtH",
        "colab_type": "code",
        "outputId": "57cd6f9b-06c9-4215-93d9-84ac787fe571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;MENTION&gt; lol ok thanks. anyway watcha doing?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;MENTION&gt; -- yeah, thank ya kindly!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;MENTION&gt;, is being a horrible friend. tears.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Jonas Brothers 3D Concert Movie is out on the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;MENTION&gt; k just call asap</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText\n",
              "0          1      <MENTION> lol ok thanks. anyway watcha doing?\n",
              "1          1                <MENTION> -- yeah, thank ya kindly!\n",
              "2          0      <MENTION>, is being a horrible friend. tears.\n",
              "3          0  Jonas Brothers 3D Concert Movie is out on the ...\n",
              "4          1                         <MENTION> k just call asap"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiC-jS3s90BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_text = df['SentimentText'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDEgGCn9z-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['Sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EohzqR6R9z7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_train,sentiment_test,y_train,y_test = train_test_split(\n",
        "                                                sentiment_text, y,  \n",
        "                                                test_size=0.25,  \n",
        "                                                random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HPFjFofuApV",
        "colab_type": "text"
      },
      "source": [
        "#Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLcRYC1x9z4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "tokenizer.fit_on_texts(sentiment_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iinJlu9t9z2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(sentiment_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentiment_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC9EbNxc9zzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding 1 because of  reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEbsuGnT9zt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmdRLNvVfQhk",
        "colab_type": "text"
      },
      "source": [
        "Para generar los Word Embeddings uso [Glove](https://en.wikipedia.org/wiki/GloVe_(machine_learning)), que es un conjunto preentrenado de word embeddings.\n",
        "\n",
        "*GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih46h0xa9zrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "    vocab_size = len(word_index) + 1  \n",
        "    # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        for line in f:\n",
        "            word, *vector = line.split()\n",
        "            if word in word_index:\n",
        "                idx = word_index[word] \n",
        "                embedding_matrix[idx] = np.array(\n",
        "                    vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-Epcl49-wa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = create_embedding_matrix('data/glove_word_embeddings/glove.6B.50d.txt' ,\n",
        "                                            tokenizer.word_index,  \n",
        "                                            embedding_dim_glove)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAXbA-8Zd9Cf",
        "colab_type": "text"
      },
      "source": [
        "## Red Neuronal Convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2QGsAVFZ4P",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/saarthi-ai/sentence-classification-using-convolutional-neural-networks-ddad72c7048c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFeLRMx3-wYK",
        "colab_type": "code",
        "outputId": "750f0496-3102-4972-cf00-1969591253c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,220,529\n",
            "Trainable params: 1,220,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0f5g51Ue5A2",
        "colab_type": "text"
      },
      "source": [
        "Con todo el dataset se tarda un rato en entrenar (aprox 8 minutos por época), con el dataset pequeño 5s por época."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlGUSIRP-wRe",
        "colab_type": "code",
        "outputId": "41df4fd9-a42d-451c-e06f-430d17c51051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=16)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7500 samples, validate on 2500 samples\n",
            "Epoch 1/50\n",
            "7500/7500 [==============================] - 3s 385us/step - loss: 0.0243 - acc: 0.9925 - val_loss: 1.0594 - val_acc: 0.6948\n",
            "Epoch 2/50\n",
            "7500/7500 [==============================] - 3s 377us/step - loss: 0.0153 - acc: 0.9949 - val_loss: 1.1956 - val_acc: 0.7168\n",
            "Epoch 3/50\n",
            "7500/7500 [==============================] - 3s 387us/step - loss: 0.0140 - acc: 0.9949 - val_loss: 1.2827 - val_acc: 0.7156\n",
            "Epoch 4/50\n",
            "7500/7500 [==============================] - 3s 380us/step - loss: 0.0119 - acc: 0.9960 - val_loss: 1.3470 - val_acc: 0.7092\n",
            "Epoch 5/50\n",
            "7500/7500 [==============================] - 3s 392us/step - loss: 0.0132 - acc: 0.9947 - val_loss: 1.3769 - val_acc: 0.7144\n",
            "Epoch 6/50\n",
            "7500/7500 [==============================] - 3s 387us/step - loss: 0.0118 - acc: 0.9956 - val_loss: 1.5186 - val_acc: 0.7236\n",
            "Epoch 7/50\n",
            "7500/7500 [==============================] - 3s 383us/step - loss: 0.0137 - acc: 0.9945 - val_loss: 1.7310 - val_acc: 0.7116\n",
            "Epoch 8/50\n",
            "7500/7500 [==============================] - 3s 386us/step - loss: 0.0403 - acc: 0.9852 - val_loss: 1.7002 - val_acc: 0.7204\n",
            "Epoch 9/50\n",
            "7500/7500 [==============================] - 3s 388us/step - loss: 0.0298 - acc: 0.9887 - val_loss: 1.7083 - val_acc: 0.7176\n",
            "Epoch 10/50\n",
            "7500/7500 [==============================] - 3s 383us/step - loss: 0.0142 - acc: 0.9947 - val_loss: 1.7515 - val_acc: 0.7108\n",
            "Epoch 11/50\n",
            "7500/7500 [==============================] - 3s 383us/step - loss: 0.0106 - acc: 0.9961 - val_loss: 1.7599 - val_acc: 0.7096\n",
            "Epoch 12/50\n",
            "7500/7500 [==============================] - 3s 387us/step - loss: 0.0086 - acc: 0.9960 - val_loss: 1.7977 - val_acc: 0.7096\n",
            "Epoch 13/50\n",
            "7500/7500 [==============================] - 3s 386us/step - loss: 0.0088 - acc: 0.9960 - val_loss: 1.7994 - val_acc: 0.7088\n",
            "Epoch 14/50\n",
            "7500/7500 [==============================] - 3s 385us/step - loss: 0.0087 - acc: 0.9963 - val_loss: 1.7944 - val_acc: 0.7108\n",
            "Epoch 15/50\n",
            "7500/7500 [==============================] - 3s 381us/step - loss: 0.0084 - acc: 0.9963 - val_loss: 1.8593 - val_acc: 0.7072\n",
            "Epoch 16/50\n",
            "7500/7500 [==============================] - 3s 373us/step - loss: 0.0084 - acc: 0.9963 - val_loss: 1.8196 - val_acc: 0.7088\n",
            "Epoch 17/50\n",
            "7500/7500 [==============================] - 3s 366us/step - loss: 0.0080 - acc: 0.9965 - val_loss: 1.9116 - val_acc: 0.7112\n",
            "Epoch 18/50\n",
            "7500/7500 [==============================] - 3s 377us/step - loss: 0.0083 - acc: 0.9965 - val_loss: 1.9352 - val_acc: 0.7140\n",
            "Epoch 19/50\n",
            "7500/7500 [==============================] - 3s 369us/step - loss: 0.0081 - acc: 0.9963 - val_loss: 1.9792 - val_acc: 0.7028\n",
            "Epoch 20/50\n",
            "7500/7500 [==============================] - 3s 384us/step - loss: 0.0551 - acc: 0.9817 - val_loss: 2.1476 - val_acc: 0.6968\n",
            "Epoch 21/50\n",
            "7500/7500 [==============================] - 3s 371us/step - loss: 0.0185 - acc: 0.9928 - val_loss: 2.0660 - val_acc: 0.6932\n",
            "Epoch 22/50\n",
            "7500/7500 [==============================] - 3s 371us/step - loss: 0.0093 - acc: 0.9960 - val_loss: 2.1030 - val_acc: 0.7128\n",
            "Epoch 23/50\n",
            "7500/7500 [==============================] - 3s 368us/step - loss: 0.0073 - acc: 0.9965 - val_loss: 2.1269 - val_acc: 0.7036\n",
            "Epoch 24/50\n",
            "7500/7500 [==============================] - 3s 368us/step - loss: 0.0074 - acc: 0.9967 - val_loss: 2.1385 - val_acc: 0.7076\n",
            "Epoch 25/50\n",
            "7500/7500 [==============================] - 3s 373us/step - loss: 0.0073 - acc: 0.9965 - val_loss: 2.1289 - val_acc: 0.7092\n",
            "Epoch 26/50\n",
            "7500/7500 [==============================] - 3s 375us/step - loss: 0.0075 - acc: 0.9967 - val_loss: 2.1342 - val_acc: 0.7072\n",
            "Epoch 27/50\n",
            "7500/7500 [==============================] - 3s 376us/step - loss: 0.0071 - acc: 0.9967 - val_loss: 2.1665 - val_acc: 0.7072\n",
            "Epoch 28/50\n",
            "7500/7500 [==============================] - 3s 375us/step - loss: 0.0071 - acc: 0.9965 - val_loss: 2.2095 - val_acc: 0.7016\n",
            "Epoch 29/50\n",
            "7500/7500 [==============================] - 3s 380us/step - loss: 0.0075 - acc: 0.9964 - val_loss: 2.1967 - val_acc: 0.7104\n",
            "Epoch 30/50\n",
            "7500/7500 [==============================] - 3s 374us/step - loss: 0.0075 - acc: 0.9967 - val_loss: 2.2135 - val_acc: 0.7080\n",
            "Epoch 31/50\n",
            "7500/7500 [==============================] - 3s 372us/step - loss: 0.0074 - acc: 0.9963 - val_loss: 2.2121 - val_acc: 0.7088\n",
            "Epoch 32/50\n",
            "7500/7500 [==============================] - 3s 380us/step - loss: 0.0071 - acc: 0.9967 - val_loss: 2.2244 - val_acc: 0.7076\n",
            "Epoch 33/50\n",
            "7500/7500 [==============================] - 3s 372us/step - loss: 0.0071 - acc: 0.9965 - val_loss: 2.2984 - val_acc: 0.7116\n",
            "Epoch 34/50\n",
            "7500/7500 [==============================] - 3s 386us/step - loss: 0.0075 - acc: 0.9968 - val_loss: 2.2940 - val_acc: 0.7064\n",
            "Epoch 35/50\n",
            "7500/7500 [==============================] - 3s 386us/step - loss: 0.0071 - acc: 0.9965 - val_loss: 2.3271 - val_acc: 0.7076\n",
            "Epoch 36/50\n",
            "7500/7500 [==============================] - 3s 393us/step - loss: 0.0071 - acc: 0.9964 - val_loss: 2.3761 - val_acc: 0.7120\n",
            "Epoch 37/50\n",
            "7500/7500 [==============================] - 3s 387us/step - loss: 0.0072 - acc: 0.9964 - val_loss: 2.4866 - val_acc: 0.7116\n",
            "Epoch 38/50\n",
            "7500/7500 [==============================] - 3s 369us/step - loss: 0.0481 - acc: 0.9829 - val_loss: 1.8441 - val_acc: 0.6988\n",
            "Epoch 39/50\n",
            "7500/7500 [==============================] - 3s 378us/step - loss: 0.0124 - acc: 0.9948 - val_loss: 2.0944 - val_acc: 0.6996\n",
            "Epoch 40/50\n",
            "7500/7500 [==============================] - 3s 377us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 2.1236 - val_acc: 0.7024\n",
            "Epoch 41/50\n",
            "7500/7500 [==============================] - 3s 368us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 2.1286 - val_acc: 0.7028\n",
            "Epoch 42/50\n",
            "7500/7500 [==============================] - 3s 375us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 2.1529 - val_acc: 0.7040\n",
            "Epoch 43/50\n",
            "7500/7500 [==============================] - 3s 381us/step - loss: 0.0067 - acc: 0.9968 - val_loss: 2.1905 - val_acc: 0.7016\n",
            "Epoch 44/50\n",
            "7500/7500 [==============================] - 3s 371us/step - loss: 0.0068 - acc: 0.9967 - val_loss: 2.2015 - val_acc: 0.7040\n",
            "Epoch 45/50\n",
            "7500/7500 [==============================] - 3s 371us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 2.1905 - val_acc: 0.7000\n",
            "Epoch 46/50\n",
            "7500/7500 [==============================] - 3s 382us/step - loss: 0.0068 - acc: 0.9967 - val_loss: 2.2111 - val_acc: 0.7012\n",
            "Epoch 47/50\n",
            "7500/7500 [==============================] - 3s 371us/step - loss: 0.0072 - acc: 0.9965 - val_loss: 2.2213 - val_acc: 0.6912\n",
            "Epoch 48/50\n",
            "7500/7500 [==============================] - 3s 377us/step - loss: 0.0068 - acc: 0.9967 - val_loss: 2.1929 - val_acc: 0.7000\n",
            "Epoch 49/50\n",
            "7500/7500 [==============================] - 3s 373us/step - loss: 0.0067 - acc: 0.9967 - val_loss: 2.2816 - val_acc: 0.7068\n",
            "Epoch 50/50\n",
            "7500/7500 [==============================] - 3s 380us/step - loss: 0.0068 - acc: 0.9968 - val_loss: 2.2732 - val_acc: 0.7036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8-9YuQW-wNW",
        "colab_type": "code",
        "outputId": "4b3a4a6b-1ffb-4354-d1d0-ce698adc3749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluamos\n",
        "train_acc = model.evaluate(X_train, y_train)[1]\n",
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 0s 59us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1PH4pQmQ-J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para poder usar las funciones de matriz de confusion y demás\n",
        "\n",
        "prediccion = convertir_prediccion_en_array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWOzhF7OQ-Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(y_test, prediccion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro4FxN9UQ-Cq",
        "colab_type": "code",
        "outputId": "a4750052-601e-40dc-f23f-5bddad7e14ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_confusion_matrix(confmat)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngANAQQIOAAUJOAAUJOAAUND/B7//BHLYPgibAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBCSuvvoQ9_0",
        "colab_type": "code",
        "outputId": "8b456cd0-7dbf-4b28-e469-846f2b920874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "metricas = calcula_metricas(confmat, plot=False)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC:  0.7036\n",
            "SEN:  0.7406896551724138\n",
            "ESP:  0.6523809523809524\n",
            "PPV:  0.7463516330785267\n",
            "FSC:  0.7435098650051921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVkiNggXl7pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_acc = metricas[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTV5yRYsQ98u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo = pd.read_csv(RESULTS_FILE)\n",
        "resultadosModelo = resultadosModelo.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en7hTz0e9zjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultado = ['CNN - Small Dataset', '-', train_acc, test_acc, confmat, metricas]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2PaGC0z9zgW",
        "colab_type": "code",
        "outputId": "eb8f8359-6f82-453e-d861-0becc60cfb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "add_row(resultadosModelo, resultado)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>parametros-optimos</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>acc_sen_esp_ppv_fsc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN - Small Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.996933</td>\n",
              "      <td>0.703600</td>\n",
              "      <td>[[685, 365], [376, 1074]]</td>\n",
              "      <td>[0.7036, 0.7406896551724138, 0.652380952380952...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM - Small Dataset</td>\n",
              "      <td>{'svm__C': 5.994842503189409, 'svm__gamma': 0....</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.733000</td>\n",
              "      <td>[[ 799  507]\\n [ 294 1400]]</td>\n",
              "      <td>[0.733, 0.8264462809917356, 0.611791730474732,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bayes - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'char', 'vect__max_df': 1.0...</td>\n",
              "      <td>0.717000</td>\n",
              "      <td>0.722333</td>\n",
              "      <td>[[ 909  397]\\n [ 436 1258]]</td>\n",
              "      <td>[0.7223333333333334, 0.7426210153482881, 0.696...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.653286</td>\n",
              "      <td>0.649667</td>\n",
              "      <td>[[ 479  827]\\n [ 224 1470]]</td>\n",
              "      <td>[0.6496666666666666, 0.8677685950413223, 0.366...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forestyes - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 23, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.668857</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>[[ 630  676]\\n [ 329 1365]]</td>\n",
              "      <td>[0.665, 0.8057851239669421, 0.4823889739663093...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Boosted Tree - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.714857</td>\n",
              "      <td>0.728667</td>\n",
              "      <td>[[ 784  522]\\n [ 292 1402]]</td>\n",
              "      <td>[0.7286666666666667, 0.8276269185360094, 0.600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bayes - Lemma - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'word', 'vect__max_df': 0.5...</td>\n",
              "      <td>0.686670</td>\n",
              "      <td>0.690333</td>\n",
              "      <td>[[ 704  602]\\n [ 327 1367]]</td>\n",
              "      <td>[0.6903333333333334, 0.806965761511216, 0.5390...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Decision Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.650236</td>\n",
              "      <td>0.647333</td>\n",
              "      <td>[[ 362  944]\\n [ 114 1580]]</td>\n",
              "      <td>[0.6473333333333333, 0.9327036599763873, 0.277...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Random Forestyes - Lemma - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 28, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.660237</td>\n",
              "      <td>0.664667</td>\n",
              "      <td>[[ 562  744]\\n [ 262 1432]]</td>\n",
              "      <td>[0.6646666666666666, 0.8453364817001181, 0.430...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Boosted Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.686955</td>\n",
              "      <td>0.701333</td>\n",
              "      <td>[[ 692  614]\\n [ 282 1412]]</td>\n",
              "      <td>[0.7013333333333334, 0.833530106257379, 0.5298...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SVM - Lemma - Small Dataset</td>\n",
              "      <td>{'svm__C': 1.0, 'svm__gamma': 0.03162277660168...</td>\n",
              "      <td>0.665524</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>[[ 508  798]\\n [ 147 1547]]</td>\n",
              "      <td>[0.685, 0.9132231404958677, 0.3889739663093415...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CNN - Big Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.927431</td>\n",
              "      <td>0.761541</td>\n",
              "      <td>[[ 7141  3821]\\n [ 2140 11896]]</td>\n",
              "      <td>[0.7615409232738619, 0.847534910230835, 0.6514...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CNN - Small Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.992667</td>\n",
              "      <td>0.706400</td>\n",
              "      <td>[[ 682  368]\\n [ 366 1084]]</td>\n",
              "      <td>[0.7064, 0.7475862068965518, 0.649523809523809...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Modelo  ...                                acc_sen_esp_ppv_fsc\n",
              "0                        CNN - Small Dataset  ...  [0.7036, 0.7406896551724138, 0.652380952380952...\n",
              "1                        SVM - Small Dataset  ...  [0.733, 0.8264462809917356, 0.611791730474732,...\n",
              "2                      Bayes - Small Dataset  ...  [0.7223333333333334, 0.7426210153482881, 0.696...\n",
              "3              Decision Tree - Small Dataset  ...  [0.6496666666666666, 0.8677685950413223, 0.366...\n",
              "4           Random Forestyes - Small Dataset  ...  [0.665, 0.8057851239669421, 0.4823889739663093...\n",
              "5               Boosted Tree - Small Dataset  ...  [0.7286666666666667, 0.8276269185360094, 0.600...\n",
              "6              Bayes - Lemma - Small Dataset  ...  [0.6903333333333334, 0.806965761511216, 0.5390...\n",
              "7      Decision Tree - Lemma - Small Dataset  ...  [0.6473333333333333, 0.9327036599763873, 0.277...\n",
              "8   Random Forestyes - Lemma - Small Dataset  ...  [0.6646666666666666, 0.8453364817001181, 0.430...\n",
              "9       Boosted Tree - Lemma - Small Dataset  ...  [0.7013333333333334, 0.833530106257379, 0.5298...\n",
              "10               SVM - Lemma - Small Dataset  ...  [0.685, 0.9132231404958677, 0.3889739663093415...\n",
              "11                         CNN - Big Dataset  ...  [0.7615409232738619, 0.847534910230835, 0.6514...\n",
              "12                       CNN - Small Dataset  ...  [0.7064, 0.7475862068965518, 0.649523809523809...\n",
              "\n",
              "[13 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9RVeMqAmgtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo.to_csv(RESULTS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKJFBWtL6LJ",
        "colab_type": "text"
      },
      "source": [
        "## LSTM (Intento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiOFPNTCMfH9",
        "colab_type": "text"
      },
      "source": [
        "Algo estoy haciendo mal y no doy con la tecla....\n",
        "\n",
        "Por algún motivo que no entiendo, haga la red que haga, la red converge a dar a todas las entradas la misma salida.\n",
        "\n",
        "Mañana lo pienso mejor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H23Ue_q-F4Pi",
        "colab_type": "code",
        "outputId": "5d6e42a2-2711-4092-d31a-9e51941d50d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=2))\n",
        "model.add(layers.LSTM(100))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 100, 32)           9632      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 50, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 1,218,134\n",
            "Trainable params: 1,218,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T98flCp7jq23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3fc6a4f7-a8ec-4c9f-e874-63f2b8209968"
      },
      "source": [
        "y_train_2d.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC3fHBNrGlB4",
        "colab_type": "code",
        "outputId": "8a219aad-4c61-4e40-99d6-8e730e5c6728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "\n",
        "history = model.fit(X_train, y_train_2d, validation_data=(X_test, y_test_2d), epochs=3, batch_size=64)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7500 samples, validate on 2500 samples\n",
            "Epoch 1/3\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 0.6869 - acc: 0.5593 - val_loss: 0.6821 - val_acc: 0.5800\n",
            "Epoch 2/3\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 0.6866 - acc: 0.5596 - val_loss: 0.6819 - val_acc: 0.5800\n",
            "Epoch 3/3\n",
            "7500/7500 [==============================] - 11s 2ms/step - loss: 0.6862 - acc: 0.5596 - val_loss: 0.6833 - val_acc: 0.5800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXG3a13-Iegw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G6ZUGCdIecx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "248c6a7c-2d37-4668-c4ca-c35a1d57d7bf"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5416635 , 0.4583364 ],\n",
              "       [0.54166377, 0.45833626],\n",
              "       [0.54166347, 0.45833647],\n",
              "       ...,\n",
              "       [0.5416637 , 0.45833626],\n",
              "       [0.54166377, 0.45833623],\n",
              "       [0.5416638 , 0.4583362 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsfLVS6WIeZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d156025-dca3-4097-e6d0-89c852634a0f"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dxyp-j4IeWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KApokpKtIeT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VF6frhiIeQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic2IcPHhIeN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw7DxAhfEsSr",
        "colab_type": "code",
        "outputId": "6b56edc7-7155-4758-fee4-e6154c438f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train_2d.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3AQts4qMb0T",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IeDTCMfZg0",
        "colab_type": "text"
      },
      "source": [
        "# Fragmentos de codigo para ver si saco algo (DRAFT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0yjzULBKM-8",
        "colab_type": "text"
      },
      "source": [
        "## 1.2.2 Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MenJhgt8F8NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers import Input, Embedding, Concatenate\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys9hYdkNefO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = maxlen\n",
        "EMBEDDING_DIM = embedding_dim\n",
        "len(w2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u15P1yOneaP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(len(w2id) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBQbun2wdsSh",
        "colab_type": "code",
        "outputId": "2704e8fe-e845-482d-f8d6-5f82d6d21b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
        "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "l_flat = Flatten()(l_pool3)\n",
        "l_dense = Dense(128, activation='relu')(l_flat)\n",
        "preds = Dense(len(macronum), activation='softmax')(l_dense)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 2 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,2,1,128].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4e54347c9f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_cov1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml_cov2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ml_pool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_cov2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0ml_cov3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_pool2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0ml_pool3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_cov3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# global max pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_axis\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# remove dummy last dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    111\u001b[0m                           padding, data_format):\n\u001b[1;32m    112\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m--> 113\u001b[0;31m                           padding, data_format, pool_mode='max')\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   4267\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   4268\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4269\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   4270\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4271\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   3754\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3755\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3756\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5670\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5671\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5672\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5673\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5674\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 2 for 'max_pooling1d_2/MaxPool' (op: 'MaxPool') with input shapes: [?,2,1,128]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idOrqVHeKYQz",
        "colab_type": "code",
        "outputId": "1348eebe-3ec2-404f-e13b-8f45f55075a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "input_layer = Input(shape=(maxlen,) )# maxlen\n",
        "embedding = Embedding(output_dim=embedding_dim, input_dim=len(w2id), input_length=maxlen)(input_layer)#w2id maxlen\n",
        "\n",
        "conv_1 = Conv1D(filters=50, kernel_size=1, strides=1, activation='relu', padding='valid')(embedding)\n",
        "mp_1 = GlobalMaxPooling1D()(conv_1)\n",
        "\n",
        "conv_2 = Conv1D(filters=50, kernel_size=2, strides=1, activation='relu', padding='valid')(embedding)\n",
        "mp_2 = GlobalMaxPooling1D()(conv_2)\n",
        "\n",
        "conv_5 = Conv1D(filters=50, kernel_size=5, strides=1, activation='relu', padding='valid')(embedding)\n",
        "mp_5 = GlobalMaxPooling1D()(conv_5)\n",
        "\n",
        "doc_representation = Concatenate()([mp_1, mp_2, mp_5])\n",
        "\n",
        "dense_1 = Dense(100, activation='relu')(doc_representation)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(100, activation='relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "out = Dense(len(l2id), activation='softmax')(drop_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 34)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 100)      1628100     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 34, 50)       5050        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 33, 50)       10050       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 30, 50)       25050       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 50)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 50)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 50)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 150)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          15100       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 100)          10100       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            202         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,693,652\n",
            "Trainable params: 1,693,652\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP7OY0FtgP2k",
        "colab_type": "code",
        "outputId": "53a90b20-d4ef-4697-98f6-1fdf857a2406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "print(splits['train'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6656.  4920.  7875. ...     0.     0.     0.]\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]\n",
            " ...\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]\n",
            " [ 9182.  8604. 14341. ...     0.     0.     0.]\n",
            " [ 9182.  9703. 14341. ...     0.     0.     0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFr0AQx9KYH8",
        "colab_type": "code",
        "outputId": "e52325eb-9b70-4157-f181-61707ef21281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(splits['train'][0].shape)\n",
        "print(splits['train'][1].shape)\n",
        "    \n",
        "\n",
        "model.fit(splits['train'][0], splits['train'][1],\n",
        "          epochs=10,\n",
        "          batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7772, 34)\n",
            "(7772, 2)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "7772/7772 [==============================] - 16s 2ms/step - loss: 0.6662 - acc: 0.6020\n",
            "Epoch 2/10\n",
            "7772/7772 [==============================] - 14s 2ms/step - loss: 0.5886 - acc: 0.6981\n",
            "Epoch 3/10\n",
            "7772/7772 [==============================] - 14s 2ms/step - loss: 0.6284 - acc: 0.6971\n",
            "Epoch 4/10\n",
            "7772/7772 [==============================] - 15s 2ms/step - loss: 3.4518 - acc: 0.6143\n",
            "Epoch 5/10\n",
            "7772/7772 [==============================] - 17s 2ms/step - loss: 6.8469 - acc: 0.5704\n",
            "Epoch 6/10\n",
            "7772/7772 [==============================] - 15s 2ms/step - loss: 7.5071 - acc: 0.5306\n",
            "Epoch 7/10\n",
            "7772/7772 [==============================] - 15s 2ms/step - loss: 9.1049 - acc: 0.4349\n",
            "Epoch 8/10\n",
            "7772/7772 [==============================] - 13s 2ms/step - loss: 8.8911 - acc: 0.4476\n",
            "Epoch 9/10\n",
            "7772/7772 [==============================] - 13s 2ms/step - loss: 7.8750 - acc: 0.5094\n",
            "Epoch 10/10\n",
            "7772/7772 [==============================] - 13s 2ms/step - loss: 9.0265 - acc: 0.4397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f24d4a4ee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXuwzJrQKXxz",
        "colab_type": "code",
        "outputId": "3d56c477-eac7-4403-afc8-7ae14eb3e233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_acc = model.evaluate(splits['train'][0], splits['train'][1])[1]\n",
        "prediction = model.predict(splits['test'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7772/7772 [==============================] - 1s 128us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPNTcTZhKXul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)\n",
        "testeo = convertir_prediccion_en_array(splits['test'][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcLiDZxzKXrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(testeo, prediccion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPQKgLvaKXoc",
        "colab_type": "code",
        "outputId": "2fff593b-7330-484e-e518-f0845f47e112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "source": [
        "metricas = calcula_metricas(confmat)\n",
        "test_acc = metricas[0]\n",
        "plot_confusion_matrix(confmat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC:  0.4333504889346372\n",
            "SEN:  1.0\n",
            "ESP:  0.0\n",
            "PPV:  0.4333504889346372\n",
            "FSC:  0.6046678635547577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1CDDXZIaZLhLUoMMd0lqkOEuSQ36/9dOiiTnXNL9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0BDAg4ADf1/Ri7qf+twXqQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZfc5s4KXgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultado = ['CNN - Small Dataset', '-', train_acc, test_acc,\n",
        "             confmat, metricas]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFGTDT_EOva5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(splits['train'][0], splits['train'][1],\n",
        "          epochs=50,\n",
        "          batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IueINoyxJcp6",
        "colab_type": "text"
      },
      "source": [
        "## 1.2.3 Deep Averaging Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyMUf5rYHnhD",
        "colab_type": "code",
        "outputId": "3edfe4d3-0892-4495-818d-2337918a22ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(output_dim=100, input_dim=vocab_size, input_length=maxlen))\n",
        "\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(1, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_22 (Embedding)     (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 100, 100)          10100     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 100, 100)          10100     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 100, 1)            101       \n",
            "=================================================================\n",
            "Total params: 1,175,401\n",
            "Trainable params: 1,175,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTiXtyZHnXI",
        "colab_type": "code",
        "outputId": "28ea1d77-44d9-4ae6-bf44-82dfcc04ea88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "\n",
        "model.fit(X_train,y_train, batch_size=16, epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-0b1353252947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_34 to have 3 dimensions, but got array with shape (7500, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzxHmpkJP7-Y",
        "colab_type": "code",
        "outputId": "1d2f96a1-895e-47e6-dd8b-910c5073ef96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "source": [
        "input_layer = Input(shape=(maxlen,) )\n",
        "embedding = Embedding(output_dim=100, input_dim=len(w2id), input_length=maxlen)(input_layer)\n",
        "doc_representation = Lambda(mask_aware_mean, mask_aware_mean_output_shape, name='embedding_average')(embedding)\n",
        "dense_1 = Dense(100, activation='relu')(doc_representation)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(100, activation='relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "out = Dense(len(l2id), activation='softmax')(drop_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 34)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 34, 100)           1628100   \n",
            "_________________________________________________________________\n",
            "embedding_average (Lambda)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 1,648,502\n",
            "Trainable params: 1,648,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gox8sGZ_OvuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxUV4cu7Ovrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ready = []\n",
        "for x, y in tokenized_filtered:\n",
        "    sentence = np.zeros((maxlen))\n",
        "    label = np.zeros((len(labels)))\n",
        "    label[int(y)-1] = 1\n",
        "    for i, t in enumerate(x):\n",
        "        sentence[i] = w2id[t] if t in vocab_counter and vocab_counter[t]>=5 else w2id['<UNK>']\n",
        "    input_ready.append((sentence,label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv-Ifi36Ovo0",
        "colab_type": "code",
        "outputId": "a6716663-6bed-41e4-e558-484e5ad827e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_ready[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vUw6rlaOvly",
        "colab_type": "code",
        "outputId": "35ad94d2-188b-47f2-8b9a-2c51e89e1907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "splits = split_train_val_test(input_ready)\n",
        "print(splits['train'][0].shape)\n",
        "print(splits['train'][1].shape)\n",
        "splits['train'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7772, 34)\n",
            "(7772, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6656.,  4920.,  7875., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.],\n",
              "       ...,\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  8604., 14341., ...,     0.,     0.,     0.],\n",
              "       [ 9182.,  9703., 14341., ...,     0.,     0.,     0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVGNmCFrP8Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1FAukl9P8D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Average, average, Lambda\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxagPzwjP8BJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_aware_mean(x):\n",
        "    # recreate the masks - all zero rows have been masked\n",
        "    mask = K.not_equal(K.sum(K.abs(x), axis=2, keepdims=True), 0)\n",
        "    # number of that rows are not all zeros\n",
        "    n = K.sum(K.cast(mask, 'float32'), axis=1, keepdims=False)\n",
        "    # compute mask-aware mean of x\n",
        "    x_mean = K.sum(x, axis=1, keepdims=False) / n\n",
        "    return x_mean\n",
        "\n",
        "def mask_aware_mean_output_shape(input_shape):\n",
        "    shape = list(input_shape)\n",
        "    assert len(shape) == 3\n",
        "    return (shape[0], shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGr9gcb5P77W",
        "colab_type": "code",
        "outputId": "b7881461-bf39-4ca3-8463-af0b7056921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_ready = []\n",
        "for x, y in tokenized_filtered:\n",
        "    sentence = np.zeros((maxlen))\n",
        "    label = np.zeros((len(labels)))\n",
        "    label[int(y)-1] = 1\n",
        "    for i, t in enumerate(x):\n",
        "        sentence[i] = w2id[t] if t in vocab_counter and vocab_counter[t]>2 else w2id['<UNK>']\n",
        "    input_ready.append((sentence,label))\n",
        "    \n",
        "splits = split_train_val_test(input_ready)\n",
        "print(splits['train'][0].shape)\n",
        "print(splits['train'][1].shape)\n",
        "\n",
        "    \n",
        "\n",
        "model.fit(splits['train'][0], splits['train'][1],\n",
        "          epochs=50,\n",
        "          batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7772, 34)\n",
            "(7772, 2)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/50\n",
            "7772/7772 [==============================] - 5s 700us/step - loss: 0.6522 - acc: 0.6099\n",
            "Epoch 2/50\n",
            "7772/7772 [==============================] - 2s 276us/step - loss: 0.5488 - acc: 0.7307\n",
            "Epoch 3/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.5026 - acc: 0.7608\n",
            "Epoch 4/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.4760 - acc: 0.7764\n",
            "Epoch 5/50\n",
            "7772/7772 [==============================] - 2s 291us/step - loss: 0.4600 - acc: 0.7953\n",
            "Epoch 6/50\n",
            "7772/7772 [==============================] - 2s 278us/step - loss: 0.4493 - acc: 0.7979\n",
            "Epoch 7/50\n",
            "7772/7772 [==============================] - 2s 278us/step - loss: 0.4473 - acc: 0.8037\n",
            "Epoch 8/50\n",
            "7772/7772 [==============================] - 2s 276us/step - loss: 0.4314 - acc: 0.8107\n",
            "Epoch 9/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.4265 - acc: 0.8155\n",
            "Epoch 10/50\n",
            "7772/7772 [==============================] - 2s 290us/step - loss: 0.4224 - acc: 0.8163\n",
            "Epoch 11/50\n",
            "7772/7772 [==============================] - 2s 293us/step - loss: 0.4126 - acc: 0.8226\n",
            "Epoch 12/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.4083 - acc: 0.8244\n",
            "Epoch 13/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.4055 - acc: 0.8250\n",
            "Epoch 14/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.3982 - acc: 0.8341\n",
            "Epoch 15/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.3907 - acc: 0.8353\n",
            "Epoch 16/50\n",
            "7772/7772 [==============================] - 2s 277us/step - loss: 0.3827 - acc: 0.8433\n",
            "Epoch 17/50\n",
            "7772/7772 [==============================] - 2s 276us/step - loss: 0.3748 - acc: 0.8471\n",
            "Epoch 18/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.3671 - acc: 0.8515\n",
            "Epoch 19/50\n",
            "7772/7772 [==============================] - 2s 287us/step - loss: 0.3555 - acc: 0.8567\n",
            "Epoch 20/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.3452 - acc: 0.8646\n",
            "Epoch 21/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.3350 - acc: 0.8657\n",
            "Epoch 22/50\n",
            "7772/7772 [==============================] - 2s 290us/step - loss: 0.3297 - acc: 0.8704\n",
            "Epoch 23/50\n",
            "7772/7772 [==============================] - 2s 275us/step - loss: 0.3232 - acc: 0.8782\n",
            "Epoch 24/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.3032 - acc: 0.8827\n",
            "Epoch 25/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.2999 - acc: 0.8855\n",
            "Epoch 26/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.2937 - acc: 0.8882\n",
            "Epoch 27/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.2855 - acc: 0.8917\n",
            "Epoch 28/50\n",
            "7772/7772 [==============================] - 2s 279us/step - loss: 0.2785 - acc: 0.8942\n",
            "Epoch 29/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.2695 - acc: 0.8968\n",
            "Epoch 30/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.2644 - acc: 0.9012\n",
            "Epoch 31/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.2589 - acc: 0.9008\n",
            "Epoch 32/50\n",
            "7772/7772 [==============================] - 2s 272us/step - loss: 0.2503 - acc: 0.9086\n",
            "Epoch 33/50\n",
            "7772/7772 [==============================] - 2s 279us/step - loss: 0.2422 - acc: 0.9099\n",
            "Epoch 34/50\n",
            "7772/7772 [==============================] - 2s 290us/step - loss: 0.2345 - acc: 0.9108\n",
            "Epoch 35/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.2350 - acc: 0.9133\n",
            "Epoch 36/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.2278 - acc: 0.9189\n",
            "Epoch 37/50\n",
            "7772/7772 [==============================] - 2s 282us/step - loss: 0.2242 - acc: 0.9216\n",
            "Epoch 38/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.2195 - acc: 0.9207\n",
            "Epoch 39/50\n",
            "7772/7772 [==============================] - 2s 279us/step - loss: 0.2120 - acc: 0.9247\n",
            "Epoch 40/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.2140 - acc: 0.9247\n",
            "Epoch 41/50\n",
            "7772/7772 [==============================] - 2s 280us/step - loss: 0.2144 - acc: 0.9265\n",
            "Epoch 42/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.2064 - acc: 0.9272\n",
            "Epoch 43/50\n",
            "7772/7772 [==============================] - 2s 283us/step - loss: 0.1964 - acc: 0.9309\n",
            "Epoch 44/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.1934 - acc: 0.9343\n",
            "Epoch 45/50\n",
            "7772/7772 [==============================] - 2s 289us/step - loss: 0.1947 - acc: 0.9323\n",
            "Epoch 46/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.1939 - acc: 0.9327\n",
            "Epoch 47/50\n",
            "7772/7772 [==============================] - 2s 284us/step - loss: 0.1865 - acc: 0.9395\n",
            "Epoch 48/50\n",
            "7772/7772 [==============================] - 2s 285us/step - loss: 0.1889 - acc: 0.9406\n",
            "Epoch 49/50\n",
            "7772/7772 [==============================] - 2s 300us/step - loss: 0.1780 - acc: 0.9418\n",
            "Epoch 50/50\n",
            "7772/7772 [==============================] - 2s 281us/step - loss: 0.1841 - acc: 0.9407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f502c98ff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBESqdQXOvgL",
        "colab_type": "code",
        "outputId": "4c4db739-5b40-4f69-9717-9e6e6482424c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_acc = model.evaluate(splits['train'][0], splits['train'][1])[1]\n",
        "prediction = model.predict(splits['test'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7772/7772 [==============================] - 0s 44us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gqM5GbU9xyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)\n",
        "testeo = convertir_prediccion_en_array(splits['test'][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPhvesUl9xvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confmat = confusion_matrix(testeo, prediccion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA-GNic2DLB3",
        "colab_type": "code",
        "outputId": "4cc76d8a-2c45-4ae2-eb40-beb830e2aec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plot_confusion_matrix(confmat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wd+yIuzTUHUxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR7I0VyZRYyn",
        "colab_type": "code",
        "outputId": "6458d814-1085-4122-999a-5dabde13595b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "metricas = calcula_metricas(confmat)\n",
        "test_acc = metricas[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC:  0.6886258363355635\n",
            "SEN:  0.5950118764845606\n",
            "ESP:  0.7602179836512262\n",
            "PPV:  0.6549019607843137\n",
            "FSC:  0.6235220908525202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/qBmvyKmlA6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krgr_V5qF8kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo = pd.read_csv('resultados_modelos.csv')\n",
        "resultadosModelo = resultadosModelo.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8sMkz0zGi27",
        "colab_type": "code",
        "outputId": "5bb634cf-b667-4f00-ad60-66141d32c639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "resultado = ['RDN - Small Dataset', '-', train_acc, test_acc,\n",
        "             confmat, metricas]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-67efdd0780ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m resultado = ['RDN - Small Dataset', '-', train_acc, test_acc,\n\u001b[0m\u001b[1;32m      2\u001b[0m              confmat, metricas]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taNNexR_F8gG",
        "colab_type": "code",
        "outputId": "7c5fb52f-a89c-48cb-f281-605ad7d91b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "source": [
        "add_row(resultadosModelo, resultado)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>parametros-optimos</th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>acc_sen_esp_ppv_fsc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RDN - Small Dataset</td>\n",
              "      <td>-</td>\n",
              "      <td>0.956897</td>\n",
              "      <td>0.688626</td>\n",
              "      <td>[[837, 264], [341, 501]]</td>\n",
              "      <td>[0.6886258363355635, 0.5950118764845606, 0.760...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM - Small Dataset</td>\n",
              "      <td>{'svm__C': 5.994842503189409, 'svm__gamma': 0....</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.733000</td>\n",
              "      <td>[[ 799  507]\\n [ 294 1400]]</td>\n",
              "      <td>[0.733, 0.8264462809917356, 0.611791730474732,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bayes - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'char', 'vect__max_df': 1.0...</td>\n",
              "      <td>0.717000</td>\n",
              "      <td>0.722333</td>\n",
              "      <td>[[ 909  397]\\n [ 436 1258]]</td>\n",
              "      <td>[0.7223333333333334, 0.7426210153482881, 0.696...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.653286</td>\n",
              "      <td>0.649667</td>\n",
              "      <td>[[ 479  827]\\n [ 224 1470]]</td>\n",
              "      <td>[0.6496666666666666, 0.8677685950413223, 0.366...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forestyes - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 23, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.668857</td>\n",
              "      <td>0.665000</td>\n",
              "      <td>[[ 630  676]\\n [ 329 1365]]</td>\n",
              "      <td>[0.665, 0.8057851239669421, 0.4823889739663093...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Boosted Tree - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.714857</td>\n",
              "      <td>0.728667</td>\n",
              "      <td>[[ 784  522]\\n [ 292 1402]]</td>\n",
              "      <td>[0.7286666666666667, 0.8276269185360094, 0.600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bayes - Lemma - Small Dataset</td>\n",
              "      <td>{'vect__analyzer': 'word', 'vect__max_df': 0.5...</td>\n",
              "      <td>0.686670</td>\n",
              "      <td>0.690333</td>\n",
              "      <td>[[ 704  602]\\n [ 327 1367]]</td>\n",
              "      <td>[0.6903333333333334, 0.806965761511216, 0.5390...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Decision Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'tree__max_depth': 19, 'vect__analyzer': 'wor...</td>\n",
              "      <td>0.650236</td>\n",
              "      <td>0.647333</td>\n",
              "      <td>[[ 362  944]\\n [ 114 1580]]</td>\n",
              "      <td>[0.6473333333333333, 0.9327036599763873, 0.277...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Random Forestyes - Lemma - Small Dataset</td>\n",
              "      <td>{'forest__max_depth': 28, 'vect__analyzer': 'c...</td>\n",
              "      <td>0.660237</td>\n",
              "      <td>0.664667</td>\n",
              "      <td>[[ 562  744]\\n [ 262 1432]]</td>\n",
              "      <td>[0.6646666666666666, 0.8453364817001181, 0.430...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Boosted Tree - Lemma - Small Dataset</td>\n",
              "      <td>{'boosted__learning_rate': 0.1, 'boosted__max_...</td>\n",
              "      <td>0.686955</td>\n",
              "      <td>0.701333</td>\n",
              "      <td>[[ 692  614]\\n [ 282 1412]]</td>\n",
              "      <td>[0.7013333333333334, 0.833530106257379, 0.5298...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SVM - Lemma - Small Dataset</td>\n",
              "      <td>{'svm__C': 1.0, 'svm__gamma': 0.03162277660168...</td>\n",
              "      <td>0.665524</td>\n",
              "      <td>0.685000</td>\n",
              "      <td>[[ 508  798]\\n [ 147 1547]]</td>\n",
              "      <td>[0.685, 0.9132231404958677, 0.3889739663093415...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Modelo  ...                                acc_sen_esp_ppv_fsc\n",
              "0                        RDN - Small Dataset  ...  [0.6886258363355635, 0.5950118764845606, 0.760...\n",
              "1                        SVM - Small Dataset  ...  [0.733, 0.8264462809917356, 0.611791730474732,...\n",
              "2                      Bayes - Small Dataset  ...  [0.7223333333333334, 0.7426210153482881, 0.696...\n",
              "3              Decision Tree - Small Dataset  ...  [0.6496666666666666, 0.8677685950413223, 0.366...\n",
              "4           Random Forestyes - Small Dataset  ...  [0.665, 0.8057851239669421, 0.4823889739663093...\n",
              "5               Boosted Tree - Small Dataset  ...  [0.7286666666666667, 0.8276269185360094, 0.600...\n",
              "6              Bayes - Lemma - Small Dataset  ...  [0.6903333333333334, 0.806965761511216, 0.5390...\n",
              "7      Decision Tree - Lemma - Small Dataset  ...  [0.6473333333333333, 0.9327036599763873, 0.277...\n",
              "8   Random Forestyes - Lemma - Small Dataset  ...  [0.6646666666666666, 0.8453364817001181, 0.430...\n",
              "9       Boosted Tree - Lemma - Small Dataset  ...  [0.7013333333333334, 0.833530106257379, 0.5298...\n",
              "10               SVM - Lemma - Small Dataset  ...  [0.685, 0.9132231404958677, 0.3889739663093415...\n",
              "\n",
              "[11 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VkWMl4IF8dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultadosModelo.to_csv('datasets/resultados_modelos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V-yGQLUF8Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDI2lCZnF8V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCyeQlnhP8Jq",
        "colab_type": "code",
        "outputId": "0d2f3c7d-f07b-453c-e37b-080e5008cc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "input_layer = Input(shape=(maxlen,) )\n",
        "embedding = Embedding(output_dim=100, input_dim=len(w2id), input_length=maxlen)(input_layer)\n",
        "dense_1 = Dense(300, activation='relu')(embedding)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(300, activation='relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "out = Dense(len(l2id), activation='softmax')(drop_2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 34)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 34, 100)           1628100   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 34, 300)           30300     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 34, 300)           90300     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 34, 300)           0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 34, 2)             602       \n",
            "=================================================================\n",
            "Total params: 1,749,302\n",
            "Trainable params: 1,749,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsJYPIDlP8Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.layers import Flatten, Input\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsIaeIt0P8Pw",
        "colab_type": "code",
        "outputId": "ababbd6e-b74c-43e4-fe7c-dd6067d3ba24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "splits['train'][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2vCrsYLpIDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r92npAKqiCPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7253f976-3aa2-464e-e5e4-c465cd1524c6"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiO0BTJfiCK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cambia_a_2d(matriz):\n",
        "    i = 0\n",
        "    resp = []\n",
        "    while i<len(matriz):\n",
        "        if matriz[i] == 1:\n",
        "            e = [1.,0.]\n",
        "        else:\n",
        "            e = [0.,1.]\n",
        "        resp.append(e)\n",
        "        i += 1\n",
        "    return np.asarray(resp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azD8SenqiCB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_2d = cambia_a_2d(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVwDPNahi-gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_2d = cambia_a_2d(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2pbo2IwMCOq",
        "colab_type": "text"
      },
      "source": [
        "## Fragmentos de codigo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYGZa3yjIeKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6OazUaWEriy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqL5Wb4zErgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrNEzE3vErdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljx0lAL9ErZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC5xFzzcsSBS",
        "colab_type": "code",
        "outputId": "417af040-b3ae-4304-d717-35cd75285fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim , input_length = X_train.shape[1]))\n",
        "model.add(layers.SpatialDropout1D(0.4))\n",
        "model.add(layers.LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_8 (Spatial (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 196)               232848    \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 197       \n",
            "=================================================================\n",
            "Total params: 1,388,145\n",
            "Trainable params: 1,388,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5YGjNkR4gkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adapt_array(formacion):\n",
        "    i = 0\n",
        "    resp = []\n",
        "    while i<len(formacion):\n",
        "        e=float(formacion[i])\n",
        "        resp.append(e)\n",
        "        i += 1\n",
        "    return np.asarray(resp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPT9kpjl4RkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = adapt_array(y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh8zF2SP6gVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = adapt_array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7jX9B16jth",
        "colab_type": "code",
        "outputId": "a95491ed-ead8-47ac-bad7-e3ded37625ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pzwp7yY6jil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vilTfd_Pmghz",
        "colab_type": "code",
        "outputId": "c0725892-6afd-42b7-f075-a9b31fe28476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7500 samples, validate on 2500 samples\n",
            "Epoch 1/3\n",
            "7500/7500 [==============================] - 60s 8ms/step - loss: 0.6866 - acc: 0.5593 - val_loss: 0.6861 - val_acc: 0.5800\n",
            "Epoch 2/3\n",
            "7500/7500 [==============================] - 55s 7ms/step - loss: 0.6869 - acc: 0.5597 - val_loss: 0.6816 - val_acc: 0.5800\n",
            "Epoch 3/3\n",
            "7500/7500 [==============================] - 55s 7ms/step - loss: 0.6864 - acc: 0.5596 - val_loss: 0.6803 - val_acc: 0.5800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CWZKz_LqFAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjlCDgoPqE78",
        "colab_type": "code",
        "outputId": "07ae9f95-ef37-412a-e168-5d106538b92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_layer_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,220,529\n",
            "Trainable params: 1,220,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SaPcdRnqE31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrCnAuc2mgk6",
        "colab_type": "code",
        "outputId": "f44b3cc4-db8a-47cd-b767-194e86124369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 100)          1155100   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,235,601\n",
            "Trainable params: 1,235,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgiiX3N_mgef",
        "colab_type": "code",
        "outputId": "b0feded3-3eca-4d24-a3f5-6ea155367f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluamos\n",
        "train_acc = model.evaluate(X_train, y_train)[1]\n",
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 6s 819us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxmIfHqdpIJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediccion = convertir_prediccion_en_array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEdFHo28pIGS",
        "colab_type": "code",
        "outputId": "9d5dbd5a-5e03-41f7-a914-61181c72db90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "prediccion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    }
  ]
}