{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_M_PYXGXlnH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#os hago el trabajo más duro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRJ7fiaDYMqo"
   },
   "source": [
    "# Introducción \n",
    "\n",
    "La idea de la práctica es visitar aquellos temas que en cierta manera nos permitan ver más contenido del curso.\n",
    "\n",
    "La práctica esta dividida en 4 o 5 subapartados, que ya tenéis en este mismo Notebook. Estos subapartados estan aquí para que rellenéis el código que hace falta para la realización de la práctica. Obviamente podéis usar tantas celdas como os hagan falta, es más es de agradecer si el código final esta algo \"limpio\". Usar funciones, algo de comentario, etc, etc...\n",
    "\n",
    "Usaremos 2 datasets, uno para el primer ejercicio, y otro para el resto de ejercicios.\n",
    "\n",
    "Ejercicios:\n",
    "\n",
    "\n",
    "1.   Machine Learning vs Deep Learning (Acordaros que hay que implementar el pipeline visto en clase entero)\n",
    "\n",
    "    1.1. Implementación de un modelo de Sentiment Analysis con algún algoritmo de Machine Learning Clásico.\n",
    "    \n",
    "    1.2. Implementación de un modelo de Sentiment Analysis con alguna arquitectura de Deep Learning.\n",
    "    \n",
    "    1.3. Breve Comparación de resultados. Confusion Matrix.\n",
    "    \n",
    "2. Hacer Analysis de los tweets del segundo dataset. Que temas aparecen? Como se representan estos temas? De que hablan unos y otros?\n",
    "\n",
    "3. Escoged a uno de los dos presidentes, y escribid tweets como ellos, usando un Modelo Generativo.\n",
    "\n",
    "En cada ejercicio, espero explicaciones y razonamientos del porque una arquitectura y no otra, por ejemplo en Deep Learning, porque usar Convolutionals en lugar de recurrentes, o en Machine Learning, Bayes en lugar de SVM. Hay que explicar el pipeline, sobretodo el preproceso de datos, con lo que habrá que hacer un pequeño estudio de que datos tenemos, y si hay cosas que se pueden ignorar, si hacéis stemming, o no, etc, etc...\n",
    "\n",
    "Acordaros de que objetivo final no es que obtengáis una accuracy brutal, es que comprendais que pasa cuando usais un algoritmo u otro, y que problemas o beneficios nos dan.\n",
    "\n",
    "![](https://i.pinimg.com/736x/19/63/8c/19638c0b33e2f7822d6806ce31d89d84--funny-cartoons-funny-jokes.jpg =400x)\n",
    "\n",
    "Mucha suerte y ánimo!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMESTLF1YMyO"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "Breve explicación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "colab_type": "code",
    "id": "9MFulRoGYGdJ",
    "outputId": "a1fef533-5462-4a4f-bfbb-7a24a29b4140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       13335192 kB\r\n",
      "MemFree:          850204 kB\r\n",
      "MemAvailable:   12678612 kB\r\n",
      "Buffers:          134936 kB\r\n",
      "Cached:         11362636 kB\r\n",
      "SwapCached:            0 kB\r\n",
      "Active:           497936 kB\r\n",
      "Inactive:       11259572 kB\r\n",
      "Active(anon):     233264 kB\r\n",
      "Inactive(anon):      284 kB\r\n",
      "Active(file):     264672 kB\r\n",
      "Inactive(file): 11259288 kB\r\n",
      "Unevictable:           0 kB\r\n",
      "Mlocked:               0 kB\r\n",
      "SwapTotal:             0 kB\r\n",
      "SwapFree:              0 kB\r\n",
      "Dirty:               656 kB\r\n",
      "Writeback:             0 kB\r\n",
      "AnonPages:        260000 kB\r\n",
      "Mapped:           145752 kB\r\n",
      "Shmem:               696 kB\r\n",
      "Slab:             662696 kB\r\n",
      "SReclaimable:     630588 kB\r\n",
      "SUnreclaim:        32108 kB\r\n",
      "KernelStack:        3008 kB\r\n",
      "PageTables:         3976 kB\r\n",
      "NFS_Unstable:          0 kB\r\n",
      "Bounce:                0 kB\r\n",
      "WritebackTmp:          0 kB\r\n",
      "CommitLimit:     6667596 kB\r\n",
      "Committed_AS:    1281840 kB\r\n",
      "VmallocTotal:   34359738367 kB\r\n",
      "VmallocUsed:           0 kB\r\n",
      "VmallocChunk:          0 kB\r\n",
      "AnonHugePages:         0 kB\r\n",
      "ShmemHugePages:        0 kB\r\n",
      "ShmemPmdMapped:        0 kB\r\n",
      "HugePages_Total:       0\r\n",
      "HugePages_Free:        0\r\n",
      "HugePages_Rsvd:        0\r\n",
      "HugePages_Surp:        0\r\n",
      "Hugepagesize:       2048 kB\r\n",
      "DirectMap4k:       63436 kB\r\n",
      "DirectMap2M:     3082240 kB\r\n",
      "DirectMap1G:    12582912 kB\r\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHZSaUfsYM0z"
   },
   "source": [
    "# Práctica/Código a entregar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPw8jkZDYvqx"
   },
   "source": [
    "## Pre-train Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Evszh16eYvxF"
   },
   "source": [
    "## Sentiment Analysis with Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvMjfdw5ZrUN"
   },
   "outputs": [],
   "source": [
    "#Code aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vthF8k2EYv6Y"
   },
   "source": [
    "## Tweet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEiVY7foZrtU"
   },
   "outputs": [],
   "source": [
    "#Code aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cppYsQrSYwCw"
   },
   "source": [
    "## Tweet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TshyDxMyZsJ0"
   },
   "outputs": [],
   "source": [
    "#Code aquí ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKAIH4nkZvid"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PracticaTemplate.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
